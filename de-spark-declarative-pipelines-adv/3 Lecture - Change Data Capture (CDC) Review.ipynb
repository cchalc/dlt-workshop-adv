{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cd7eb81-c485-41ee-bb07-4a8fd8db226c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# INCLUDE_HEADER_TRUE\n",
    "# INCLUDE_FOOTER_TRUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0eae95da-8699-4a6f-b5b3-9db496881c6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Lecture - Change Data Capture (CDC) Review\n",
    "\n",
    "This lecture provides a comprehensive review of Change Data Capture (CDC) concepts and implementation patterns in the Lakehouse. You'll explore how CDC enables real-time data synchronization and learn about different approaches to handling changing data.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lecture, you will be able to:\n",
    "\n",
    "1. **Define** Change Data Capture (CDC) and explain its role in data synchronization\n",
    "2. **Distinguish** between SCD Type 1 and SCD Type 2 patterns and their use cases\n",
    "3. **Analyze** how SCD Type 1 overwrites existing data while SCD Type 2 preserves history\n",
    "4. **Identify** when to use each SCD type based on business requirements\n",
    "5. **Recognize** how `AUTO CDC INTO` simplifies CDC implementation in Lakeflow Declarative Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f61051c-36f4-4f31-9cbe-7711e94d21c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A. What is Change Data Capture?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e4139f4-be81-4673-a8ef-b813af79c954",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<img src=\"./Includes/images/cdc_lecture/01-cdcoverview-review.png\" alt=\"CDC Overview\" width=\"1100\">\n",
    "\n",
    "\n",
    "Let's review **Change Data Capture (CDC)**, a foundational concept for keeping data synchronized across systems.\n",
    "\n",
    "#### CDC Definition and Purpose\n",
    "\n",
    "Change Data Capture is a technique used to track and capture changes in data sources like databases, Lakehouses, or data warehouses, and then apply those changes to a target table to ensure it reflects the latest state of the source.\n",
    "\n",
    "#### Slowly Changing Dimensions (SCDs)\n",
    "\n",
    "CDC is closely tied to the concept of **Slowly Changing Dimensions (SCDs)**, which describe how historical data changes are handled in your target system.\n",
    "\n",
    "We'll focus on two main types:\n",
    "- **SCD Type 1** - Overwrites existing data with new values (no history tracking)  \n",
    "- **SCD Type 2** - Preserves history by storing previous versions of records\n",
    "\n",
    "#### Real-World Example\n",
    "\n",
    "Imagine a **customer** table where new customers are added, existing customer information is updated, or some customers are deleted. CDC ensures those changes flow into the target table using either SCD Type 1 or Type 2 logic, keeping the target table continuously up to date.\n",
    "\n",
    "**Think about it:** What types of data changes occur frequently in your organization that would benefit from automated CDC processing?\n",
    "\n",
    "#### Documentation Resources\n",
    "- [What is change data capture (CDC)?](https://docs.databricks.com/aws/en/ldp/what-is-change-data-capture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62d3afc0-4444-47c5-a0a7-306121f1581b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## B. Slowly Changing Dimensions (SCD) Type 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4aceba7-e364-4a39-aa32-703abe767952",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### B1. SCD Type 1 - Overview\n",
    "\n",
    "<img src=\"./Includes/images/cdc_lecture/02-scd-type-1-02-review-slide.png\" alt=\"SCD Type 1 Example\" width=\"1100\">\n",
    "\n",
    "\n",
    "SCD Type 1 updates the **target table** by **overwriting existing rows** with the latest values. No version history is maintained - only the current state matters.\n",
    "\n",
    "#### Key Characteristics:\n",
    "- **Updates:** When a record is updated by its key(s), the existing row is replaced with new values\n",
    "- **Deletes:** When a record is deleted by its key(s), it is removed from the target table  \n",
    "- **Current State Only:** Only the most recent version of each record is stored\n",
    "- **No History:** Previous changes and historical versions are not retained\n",
    "\n",
    "#### Our Scenario Setup\n",
    "\n",
    "**Target Table (customers)** - Current customer data:\n",
    "\n",
    "| CustomerID | Name   | Address | ProcessDate |\n",
    "|------------|--------|---------|-------------|\n",
    "| 1 | Peter | 1 Blue Rd. | 5/1/2025 |\n",
    "| 2 | Samarth | 22 Front St | 5/1/2025 |\n",
    "\n",
    "**Source Updates** - Incoming changes:\n",
    "\n",
    "| Change Type | Details |\n",
    "|-------------|---------|\n",
    "| **Update** | Peter has two address updates (5/15 and 5/20) for `customer_id = 1` |\n",
    "| **Delete** | Samarth requests account removal (`customer_id = 2`) |\n",
    "| **Insert** | New customer Kostas joins (`customer_id = 3`) |\n",
    "\n",
    "**Goal:** Apply updates so the target table reflects the latest state of all customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ededccc-be6b-4833-95fd-bc6fd5e7b9e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### B2. SCD Type 1 - Implementation Example\n",
    "\n",
    "<img src=\"./Includes/images/cdc_lecture/02-scd-type-1-01-review-slide.png\" alt=\"SCD Type 1 Overview\" width=\"1100\">\n",
    "\n",
    "When we apply **SCD Type 1**, the target table is updated with the latest customer information using the **CustomerID** (key column) and **ProcessDate** (sequence column) to determine the most recent changes.\n",
    "\n",
    "#### Processing Logic:\n",
    "\n",
    "1. **Peter (CustomerID 1):** \n",
    "   - Multiple address updates exist (5/15 and 5/20)\n",
    "   - Only the latest update (5/20) with address *123 Main St.* is applied\n",
    "   - Previous address history is lost\n",
    "\n",
    "2. **Samarth (CustomerID 2):** \n",
    "   - Marked for deletion\n",
    "   - Entire row is removed from the target table\n",
    "   - No trace of the customer remains\n",
    "\n",
    "3. **Kostas (CustomerID 3):** \n",
    "   - New customer record\n",
    "   - Inserted as a new row in the target table\n",
    "\n",
    "#### Final Result:\n",
    "The customers table contains only the most current snapshot of active customers. This approach is ideal when:\n",
    "- Historical data is not required for business operations\n",
    "- Storage efficiency is prioritized\n",
    "- Regulatory compliance doesn't require audit trails\n",
    "\n",
    "**Use SCD Type 1 when:** You only need the most up-to-date and accurate information without historical context.\n",
    "\n",
    "#### Documentation\n",
    "- [Use SCD Type 1 to keep only the latest data](https://docs.databricks.com/aws/en/ldp/what-is-change-data-capture#step-2-use-scd-type-1-to-keep-only-the-latest-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bf5d2c3-73a5-400f-9ad6-94bc5c1a86a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## C. Slowly Changing Dimensions (SCD) Type 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee5dc1ca-81ec-4933-9d94-7e8a03afb07f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### C1. SCD Type 2 - Scenario\n",
    "\n",
    "<img src=\"./Includes/images/cdc_lecture/03-auto-cdc-examplescenario.png\" alt=\"SCD Type 2 - Scenario\" width=\"1100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27c8ba3c-b0cc-4461-95f9-be97f752385a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### C2. SCD Type 2 - Implementation\n",
    "<img src=\"./Includes/images/cdc_lecture/02-scd-type-2-01-review-slide.png\" alt=\"SCD Type 2\" width=\"1100\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Slowly Changing Dimensions Type 2 (SCD Type 2)** introduces **historical tracking and versioning** of records, preserving a complete audit trail of all changes over time.\n",
    "\n",
    "#### Core Principles:\n",
    "\n",
    "When a record changes:\n",
    "- **Historical Preservation:** The old record is preserved with metadata columns showing its validity period\n",
    "- **New Version Creation:** A new record is inserted with the updated information\n",
    "- **Soft Deletes:** Deleted records remain in the table but are flagged as inactive\n",
    "\n",
    "#### Metadata Columns Added:\n",
    "- **__START_AT** - Timestamp when the row became active  \n",
    "- **__END_AT** - Timestamp when the row became inactive  \n",
    "  - `NULL` **value** = currently active record\n",
    "  - **Non** `NULL` **value** = inactive/historical record\n",
    "\n",
    "#### Detailed Example Breakdown:\n",
    "\n",
    "**Customer ID 1 - Peter:**  \n",
    "- **Two records exist** for Peter in the final table\n",
    "- **Active record:** Shows Peter's current address with `__END_AT = NULL`\n",
    "- **Historical record:** Preserves his previous address with `__END_AT` populated\n",
    "\n",
    "**Customer ID 2 - Samarth:**  \n",
    "- **Account deletion** processed as a soft delete\n",
    "- **Original record remains** but `__END_AT` is populated with deletion timestamp\n",
    "- **No new record created** since this was a deletion operation\n",
    "\n",
    "**Customer ID 3 - Kostas:**  \n",
    "- **New customer insertion** creates active record\n",
    "- **__START_AT** marks when he joined, **__END_AT** remains NULL\n",
    "\n",
    "#### Business Value:\n",
    "SCD Type 2 enables complete historical analysis, allowing you to:\n",
    "- Track how customer attributes evolved over time\n",
    "- Perform point-in-time analysis for any historical date\n",
    "- Maintain compliance with audit requirements\n",
    "- Support advanced analytics on changing dimensions\n",
    "\n",
    "**Use SCD Type 2 when:** Historical data tracking is essential for business intelligence, compliance, or analytical requirements.\n",
    "\n",
    "#### Documentation\n",
    "- [Use SCD Type 2 to keep historical data](https://docs.databricks.com/aws/en/ldp/what-is-change-data-capture#step-3-use-scd-type-2-to-keep-historical-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60e9e394-c8cf-4af4-963f-5e60affd6a16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## D. Implementing CDC with `AUTO CDC INTO` in Spark Declarative Pipelines (SCD Type 1 Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2522ab5f-4d20-4aa5-bd6a-8e57bf71c361",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<img src=\"./Includes/images/cdc_lecture/03-auto-cdc-example.png\" alt=\"AUTO CDC Example\" width=\"1100\">\n",
    "\n",
    "Now that we've covered CDC concepts and both SCD patterns, let's explore how **Lakeflow Spark Declarative Pipelines** simplifies CDC implementation with the `AUTO CDC INTO` statement.\n",
    "\n",
    "**NOTE:** The `AUTO CDC` APIs were previously known as `APPLY CHANGES INTO`, but the syntax and functionality remain identical.\n",
    "\n",
    "#### AUTO CDC INTO Syntax Breakdown\n",
    "\n",
    "```sql\n",
    "CREATE OR REFRESH STREAMING TABLE customers;\n",
    "\n",
    "CREATE FLOW scd_type_1_flow AS\n",
    "AUTO CDC INTO customers \n",
    " FROM STREAM updates\n",
    " KEYS (CustomerID)                              \n",
    " APPLY AS DELETE WHEN operation = \"DELETE\"     \n",
    " SEQUENCE BY ProcessDate                 \n",
    " COLUMNS * EXCEPT (operation)  \n",
    " STORED AS SCD TYPE 1;\n",
    "```\n",
    "\n",
    "- **`AUTO CDC INTO customers`** - Specifies the target table for CDC operations\n",
    "- **`FROM STREAM updates`** - Defines the source stream containing CDC events\n",
    "- **`KEYS (CustomerID)`** - Establishes unique key(s) for matching source and target records\n",
    "- **`APPLY AS DELETE WHEN operation = \"DELETE\"`** - Defines deletion logic based on operation column\n",
    "- **`SEQUENCE BY ProcessDate`** - Ensures events are processed in chronological order\n",
    "- **`COLUMNS * EXCEPT (operation)`** - Includes all columns except operational metadata\n",
    "- **`STORED AS SCD TYPE 1`** - Specifies SCD Type 1 pattern (default is SCD Type 1 default)\n",
    "\n",
    "#### Key Advantages\n",
    "\n",
    "`AUTO CDC INTO` provides significant benefits over traditional approaches:\n",
    "\n",
    "1. **Simplified Implementation:** Eliminates complex `MERGE INTO` logic\n",
    "2. **Automatic Ordering:** Handles event sequencing automatically\n",
    "3. **Built-in SCD Support:** Native support for both Type 1 and Type 2 patterns\n",
    "4. **Streaming Integration:** Works seamlessly with both streaming and batch sources\n",
    "5. **Error Handling:** Includes robust error handling and recovery mechanisms\n",
    "\n",
    "**Reflection Question:** How might `AUTO CDC INTO` simplify your current data pipeline maintenance compared to custom merge logic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91e348db-cb0c-4363-a693-e75267d058f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## E. Documentation and Next Steps\n",
    "\n",
    "#### Key Resources:\n",
    "- [The AUTO CDC APIs: Simplify change data capture with Lakeflow Declarative Pipelines](https://docs.databricks.com/aws/en/ldp/cdc)\n",
    "- [AUTO CDC INTO (Lakeflow Declarative Pipelines)](https://docs.databricks.com/aws/en/ldp/developer/ldp-sql-ref-apply-changes-into)\n",
    "\n",
    "#### Coming Up Next:\n",
    "In the following demonstration, you'll get hands-on experience implementing both SCD Type 1 and Type 2 patterns using `AUTO CDC INTO` with real customer data scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b69a1c3-a08f-45de-aa52-4a79aafa3317",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## F. Summary and Key Takeaways\n",
    "\n",
    "### What We Covered:\n",
    "\n",
    "1. **Change Data Capture (CDC)** enables automated synchronization of data changes between systems\n",
    "2. **SCD Type 1** overwrites existing data, maintaining only current state (no history)\n",
    "3. **SCD Type 2** preserves complete historical versions using metadata columns\n",
    "4. **`AUTO CDC INTO`** provides declarative, simplified CDC implementation in Lakeflow pipelines\n",
    "\n",
    "### Decision Framework:\n",
    "\n",
    "**Choose SCD Type 1 when:**\n",
    "- Only current data state is needed\n",
    "- Storage efficiency is prioritized\n",
    "- Historical tracking is not required\n",
    "\n",
    "**Choose SCD Type 2 when:**\n",
    "- Historical analysis is essential\n",
    "- Audit trails are required for compliance\n",
    "- Point-in-time reporting is needed\n",
    "\n",
    "### Preparation for Demo - Automating SCD Type 2 with AUTO CDC in Lakeflow Spark Declarative Pipelines\n",
    "You're now ready to implement these concepts hands on in the upcoming demonstration where you'll build working CDC pipelines using both SCD patterns."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3 Lecture - Change Data Capture (CDC) Review",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
