{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af21129e-547f-47a1-ae8b-352267ead2e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Classroom-Setup-Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "200d792a-6b68-4435-9db2-8e89889c2f71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "check_required_vars(\"your_marketplace_share_catalog_name\",\"my_catalog\")\n",
    "\n",
    "def multi_flow_demo_setup(\n",
    "    my_catalog: str, \n",
    "    marketplace_catalog: str, \n",
    "    schema: str,\n",
    "    source_volumes: list,\n",
    "    reset_volume = False\n",
    "):\n",
    "\n",
    "    ## Set the default catalog\n",
    "    r = spark.sql(f\"USE CATALOG {my_catalog}\")\n",
    "\n",
    "    ## Bronze, silver, gold schemas\n",
    "    bronze_schema = f'{schema}_1_bronze'\n",
    "    print(f'Creating schema {my_catalog}.{bronze_schema}...')\n",
    "    spark.sql(f'CREATE SCHEMA IF NOT EXISTS {my_catalog}.{bronze_schema}')\n",
    "\n",
    "    silver_schema = f'{schema}_2_silver'\n",
    "    print(f'Creating schema {my_catalog}.{silver_schema}...')\n",
    "    spark.sql(f'CREATE SCHEMA IF NOT EXISTS {my_catalog}.{silver_schema}')\n",
    "\n",
    "    gold_schema = f'{schema}_3_gold'\n",
    "    print(f'Creating schema {my_catalog}.{gold_schema}...')\n",
    "    spark.sql(f'CREATE SCHEMA IF NOT EXISTS {my_catalog}.{gold_schema}')\n",
    "\n",
    "    ## Create staging volumes for each flow in the bronze schema\n",
    "    for volume in source_volumes:\n",
    "        create_volume = f'{my_catalog}.{bronze_schema}.{volume}'\n",
    "        print(f'Creating volume {volume}...')\n",
    "        spark.sql(f'CREATE VOLUME IF NOT EXISTS {create_volume}')\n",
    "\n",
    "    ## Create python varibles to volume paths\n",
    "    print('Creating Python and SQL variables to volume paths: bright_home_orders_path, lumina_sports_orders_path, northstar_outfitters_orders_path')\n",
    "\n",
    "    vol_path = f'/Volumes/{my_catalog}/{bronze_schema}'\n",
    "\n",
    "    bright_home_orders_path = f'/Volumes/{my_catalog}/{bronze_schema}/bright_home_orders'\n",
    "    lumina_sports_orders_path = f'/Volumes/{my_catalog}/{bronze_schema}/lumina_sports_orders'\n",
    "    northstar_outfitters_orders_path = f'/Volumes/{my_catalog}/{bronze_schema}/northstar_outfitters_orders'\n",
    "\n",
    "    ## Create a SQL variable to avoid using spark.sql in queries\n",
    "    spark.sql(f\"DECLARE OR REPLACE VARIABLE my_vol_path STRING DEFAULT '{vol_path}'\")\n",
    "\n",
    "    ## Delete all files in the labuser's volume to reset the class if necessary. Otherwise does nothing.\n",
    "    if reset_volume == True:\n",
    "        print('Reset volumes by deleting files')\n",
    "        delete_source_files(bright_home_orders_path + '/')\n",
    "        delete_source_files(lumina_sports_orders_path + '/')\n",
    "        delete_source_files(northstar_outfitters_orders_path + '/')\n",
    "\n",
    "\n",
    "    # Copy 1 file into each user's volume from marketplace\n",
    "    marketplace_catalog_schema = f'/Volumes/{marketplace_catalog}/v02/subsidiary_daily_orders'\n",
    "    copy_files(copy_from = f'{marketplace_catalog_schema}/bright_home_orders', copy_to = bright_home_orders_path, n = 1)\n",
    "    copy_files(copy_from = f'{marketplace_catalog_schema}/lumina_sports_orders', copy_to = lumina_sports_orders_path, n = 1)\n",
    "    copy_files(copy_from = f'{marketplace_catalog_schema}/northstar_outfitters_orders', copy_to = northstar_outfitters_orders_path, n = 1)\n",
    "\n",
    "    ## Check user's compute\n",
    "    compute_validation(recommend_dbr_classic_version=None, recommended_serverless_version=4)\n",
    "\n",
    "    ## Setup complete displayed\n",
    "    setup_complete_msg()\n",
    "\n",
    "    display_config_values([\n",
    "        ('Your Marketplace Share Catalog', marketplace_catalog),\n",
    "        ('Your Catalog', my_catalog),\n",
    "        ('Your Schemas', f\"{bronze_schema}, {silver_schema}, {gold_schema}\"),\n",
    "        ('Your Data Source Volume Path', bright_home_orders_path),\n",
    "        ('Your Data Source Volume Path', lumina_sports_orders_path),\n",
    "        ('Your Data Source Volume Path', northstar_outfitters_orders_path)\n",
    "    ])\n",
    "\n",
    "    ## Return this to path to to use in the notebook\n",
    "    return vol_path"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6237912535123452,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Classroom-Setup-multiple-flows",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
