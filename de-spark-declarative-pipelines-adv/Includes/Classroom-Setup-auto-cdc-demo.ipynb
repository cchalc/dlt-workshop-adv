{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af21129e-547f-47a1-ae8b-352267ead2e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Classroom-Setup-Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba998117-a135-46d3-8bf6-eadf5f63d434",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# # \n",
    "# import os\n",
    "\n",
    "# def create_objects_demo_scdtype2(catalog: str, schema: str, source_volume: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Sets up a Databricks lab environment for a workshop by creating a catalog, schema, \n",
    "#     and staging volume if they do not already exist.\n",
    "\n",
    "#     Args:\n",
    "#         catalog (str): The Unity Catalog name to use for the lab.\n",
    "#         schema (str): The schema name to create and use within the catalog. Will create three schemas (bronze, silver, gold).\n",
    "#         source_volume (str): The name of the source volume for lab data.\n",
    "\n",
    "#     Returns:\n",
    "#         str: The full path to the created lab source files volume.\n",
    "\n",
    "#     Raises:\n",
    "#         ValueError: If any of the input arguments are empty or invalid.\n",
    "#         Exception: If Spark execution fails during setup.\n",
    "#     \"\"\"\n",
    "     \n",
    "#     try:\n",
    "#         ## Bronze, silver, gold\n",
    "#         bronze_schema = f'{schema}_1_bronze'\n",
    "#         print(f'Creating schema {catalog}.{bronze_schema}...')\n",
    "#         spark.sql(f'CREATE SCHEMA IF NOT EXISTS {catalog}.{bronze_schema}')\n",
    "\n",
    "#         silver_schema = f'{schema}_2_silver'\n",
    "#         print(f'Creating schema {catalog}.{silver_schema}...')\n",
    "#         spark.sql(f'CREATE SCHEMA IF NOT EXISTS {catalog}.{silver_schema}')\n",
    "\n",
    "#         gold_schema = f'{schema}_3_gold'\n",
    "#         print(f'Creating schema {catalog}.{gold_schema}...')\n",
    "#         spark.sql(f'CREATE SCHEMA IF NOT EXISTS {catalog}.{gold_schema}')\n",
    "\n",
    "#         ## Create staging volume in the bronze schema\n",
    "#         create_volume = f'{catalog}.{bronze_schema}.{source_volume}'\n",
    "#         print(f'Creating volume {create_volume}...')\n",
    "#         spark.sql(f'CREATE VOLUME IF NOT EXISTS {create_volume}')\n",
    "\n",
    "#         ## Create and store the path to their volume and return\n",
    "#         volume_path = f'/Volumes/{catalog}/{bronze_schema}/{source_volume}'\n",
    "\n",
    "\n",
    "#         print('\\n---------- Schema and volume setup complete ----------\\n')\n",
    "#         # Return volume path to use in demonstration\n",
    "\n",
    "#         return volume_path\n",
    "\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(\"⚠️ Error during setup_lab_scdtype2 execution.\")\n",
    "#         print(f\"Details: {e}\")\n",
    "#         raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "200d792a-6b68-4435-9db2-8e89889c2f71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # --------------------------------------------------------\n",
    "# # DO NOT MODIFY BELOW\n",
    "# # --------------------------------------------------------\n",
    "check_required_vars(\"your_marketplace_share_catalog_name\",\"my_catalog\")\n",
    "\n",
    "def auto_cdc_demo_setup(\n",
    "    my_catalog: str, \n",
    "    marketplace_catalog: str, \n",
    "    schema: str,\n",
    "    source_volume: str,\n",
    "    reset_volume = False\n",
    "):\n",
    "\n",
    "    ## Set the default catalog\n",
    "    r = spark.sql(f\"USE CATALOG {my_catalog}\")\n",
    "\n",
    "    ## Create the user schemas and volume. Bronze, silver, gold\n",
    "    bronze_schema = f'{schema}_1_bronze'\n",
    "    print(f'Creating schema {my_catalog}.{bronze_schema}...')\n",
    "    spark.sql(f'CREATE SCHEMA IF NOT EXISTS {my_catalog}.{bronze_schema}')\n",
    "\n",
    "    silver_schema = f'{schema}_2_silver'\n",
    "    print(f'Creating schema {my_catalog}.{silver_schema}...')\n",
    "    spark.sql(f'CREATE SCHEMA IF NOT EXISTS {my_catalog}.{silver_schema}')\n",
    "\n",
    "    gold_schema = f'{schema}_3_gold'\n",
    "    print(f'Creating schema {my_catalog}.{gold_schema}...')\n",
    "    spark.sql(f'CREATE SCHEMA IF NOT EXISTS {my_catalog}.{gold_schema}')\n",
    "\n",
    "    ## Create staging volume in the bronze schema\n",
    "    create_volume = f'{my_catalog}.{bronze_schema}.{source_volume}'\n",
    "    print(f'Creating volume {create_volume}...')\n",
    "    spark.sql(f'CREATE VOLUME IF NOT EXISTS {create_volume}')\n",
    "\n",
    "    ## Create and store the path to their volume and return\n",
    "    my_vol_path = f'/Volumes/{my_catalog}/{bronze_schema}/{source_volume}'\n",
    "\n",
    "    ## Create a SQL variable to avoid using spark.sql in queries\n",
    "    spark.sql(f\"DECLARE OR REPLACE VARIABLE my_vol_path STRING DEFAULT '{my_vol_path}'\")\n",
    "\n",
    "    print('\\n---------- Schema and volume setup complete ----------\\n')\n",
    "\n",
    "\n",
    "    ## Delete all files in the labuser's volume to reset the class if necessary. Otherwise does nothing.\n",
    "    if reset_volume == True:\n",
    "        print('Reset volume by deleting files')\n",
    "        delete_source_files(f'/Volumes/{my_catalog}/{schema}_1_bronze/customer_source_files/')\n",
    "\n",
    "    # Copy 1 file into the user's volume\n",
    "    copy_files(\n",
    "        copy_from = f'/Volumes/{marketplace_catalog}/v01/retail-pipeline/customers/stream_json', \n",
    "        copy_to = f'/Volumes/{my_catalog}/{schema}_1_bronze/customer_source_files', \n",
    "        n = 1\n",
    "    )\n",
    "\n",
    "    compute_validation(recommend_dbr_classic_version=None, recommended_serverless_version=4)\n",
    "\n",
    "    ## Setup complete displayed\n",
    "    setup_complete_msg()\n",
    "\n",
    "    display_config_values([\n",
    "        ('Your Marketplace Share Catalog', marketplace_catalog),\n",
    "        ('Your Catalog', my_catalog),\n",
    "        ('Your Schemas', f\"{bronze_schema}, {silver_schema}, {gold_schema}\"),\n",
    "        ('Your Volume Path', my_vol_path)\n",
    "    ])\n",
    "\n",
    "    ## Return this to path to to use in the notebook\n",
    "    return my_vol_path"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6237912535123452,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Classroom-Setup-auto-cdc-demo",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
