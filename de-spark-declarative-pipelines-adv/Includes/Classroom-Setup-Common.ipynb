{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46969f7e-731d-48e5-9b15-53e4b35261a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def copy_files(copy_from: str, copy_to: str, n: int, sleep=2):\n",
    "    '''\n",
    "    Copy files from one location to another destination's volume.\n",
    "\n",
    "    This method performs the following tasks:\n",
    "      1. Lists files in the source directory and sorts them. Sorted to keep them in the same order when copying for consistency.\n",
    "      2. Verifies that the source directory has at least `n` files.\n",
    "      3. Copies files from the source to the destination, skipping files already present at the destination.\n",
    "      4. Pauses for `sleep` seconds after copying each file.\n",
    "      5. Stops after copying `n` files or if all files are processed.\n",
    "      6. Will print information on the files copied.\n",
    "    \n",
    "    Parameters\n",
    "    - copy_from (str): The source directory where files are to be copied from.\n",
    "    - copy_to (str): The destination directory where files will be copied to.\n",
    "    - n (int): The number of files to copy from the source. If n is larger than total files, an error is returned.\n",
    "    - sleep (int, optional): The number of seconds to pause after copying each file. Default is 2 seconds.\n",
    "\n",
    "    Returns:\n",
    "    - None: Prints information to the log on what files it's loading. If the file exists, it skips that file.\n",
    "\n",
    "    Example:\n",
    "    - copy_files(copy_from='/Volumes/gym_data/v01/user-reg', \n",
    "           copy_to=f'{DA.paths.working_dir}/pii/stream_source/user_reg',\n",
    "           n=1)\n",
    "    '''\n",
    "    import os\n",
    "    import time\n",
    "\n",
    "    print(f\"\\n----------------Loading files to user's volume: '{copy_to}'----------------\")\n",
    "      \n",
    "      # Validate that both source and destination paths exist before proceeding\n",
    "    if not os.path.exists(copy_from):\n",
    "        raise FileNotFoundError(f\"❌ Source path does not exist. Confirm you have setup the Marketplace share: {copy_from}\")\n",
    "    if not os.path.exists(copy_to):\n",
    "        raise FileNotFoundError(f\"❌ Destination path does not exist. Confirm you set a valid catalog.schema that you can write to: {copy_to}\")\n",
    "\n",
    "    ## List all files in the copy_from volume and sort the list\n",
    "    list_of_files_to_copy = sorted(os.listdir(copy_from))\n",
    "    total_files_in_copy_location = len(list_of_files_to_copy)\n",
    "\n",
    "    ## Get a list of files in the source\n",
    "    list_of_files_in_source = os.listdir(copy_to)\n",
    "\n",
    "    assert total_files_in_copy_location >= n, f\"The source location contains only {total_files_in_copy_location} files, but you specified {n}  files to copy. Please specify a number less than or equal to the total number of files available.\"\n",
    "\n",
    "    ## Looping counter\n",
    "    counter = 1\n",
    "\n",
    "    ## Load files if not found in the co\n",
    "    for file in list_of_files_to_copy:\n",
    "\n",
    "      ## If the file is found in the source, skip it with a note. Otherwise, copy file.\n",
    "      if file in list_of_files_in_source:\n",
    "        print(f'File number {counter} - {file} is already in the source volume \"{copy_to}\". Skipping file.')\n",
    "      else:\n",
    "        file_to_copy = f'{copy_from}/{file}'\n",
    "        copy_file_to = f'{copy_to}/{file}'\n",
    "        print(f'File number {counter} - Copying file {file_to_copy} --> {copy_file_to}.')\n",
    "        dbutils.fs.cp(file_to_copy, copy_file_to , recurse = True)\n",
    "        \n",
    "        ## Sleep after load\n",
    "        time.sleep(sleep) \n",
    "\n",
    "      ## Stop after n number of loops based on argument.\n",
    "      if counter == n:\n",
    "        break\n",
    "      else:\n",
    "        counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a12127cc-25c7-4c2c-84df-e8481480a7b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def delete_source_files(source_files: str):\n",
    "    \"\"\"\n",
    "    Deletes all files in the specified source volume.\n",
    "\n",
    "    This function iterates through all the files in the given volume,\n",
    "    deletes them, and prints the name of each file being deleted.\n",
    "\n",
    "    Parameters:\n",
    "    - source_files : str\n",
    "        The path to the volume containing the files to delete. \n",
    "        Use the {DA.paths.working_dir} to dynamically navigate to the user's volume location in dbacademy/ops/vocareumlab@name:\n",
    "            Example: DA.paths.working_dir = /Volumes/dbacademy/ops/vocareumlab@name\n",
    "\n",
    "    Returns:\n",
    "    - None. This function does not return any value. It performs file deletion and prints all files that it deletes. If no files are found it prints in the output.\n",
    "\n",
    "    Example:\n",
    "    - delete_source_files(f'{DA.paths.working_dir}/pii/stream_source/user_reg')\n",
    "    \"\"\"\n",
    "\n",
    "    import os\n",
    "\n",
    "    print(f'\\nSearching for files in {source_files} volume to delete prior to creating files...')\n",
    "    if os.path.exists(source_files):\n",
    "        list_of_files = sorted(os.listdir(source_files))\n",
    "    else:\n",
    "        list_of_files = None\n",
    "\n",
    "    if not list_of_files:  # Checks if the list is empty.\n",
    "        print(f\"No files found in {source_files}.\\n\")\n",
    "    else:\n",
    "        for file in list_of_files:\n",
    "            file_to_delete = source_files + file\n",
    "            print(f'Deleting file: {file_to_delete}')\n",
    "            dbutils.fs.rm(file_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc62aa1b-cf0f-42d1-831d-33007ab49c31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def delete_schemas(catalog: str, schemas: list):\n",
    "    \"\"\"\n",
    "    Prompt the user and delete the specified schemas in the given catalog\n",
    "    if they confirm with 'Y'.\n",
    "    \"\"\"\n",
    "    user_response = input(\n",
    "        f\"Are you sure you want to delete these schemas in catalog '{catalog}': {schemas}? (Y/N): \"\n",
    "    ).strip()\n",
    "\n",
    "    if user_response == 'Y':\n",
    "        print(f\"Deleting schemas {schemas} in catalog '{catalog}'...\")\n",
    "        for schema in schemas:\n",
    "            spark.sql(f\"DROP SCHEMA IF EXISTS `{catalog}`.`{schema}` CASCADE\")\n",
    "        print(\"Schemas deleted (if they existed).\")\n",
    "    else:\n",
    "        print(\"Operation cancelled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2e94f5f-8d62-450a-a0be-034bbfbe4890",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# CHECK COMPUTE FUNCTION\n",
    "#\n",
    "# The function `compute_validation(recommend_dbr_classic_version=17.3, recommended_serverless_version=1)`\n",
    "# checks the current Databricks compute type (All-Purpose or Serverless)\n",
    "# and returns WARNINGS if the user's environment does not meet the specified requirements.\n",
    "#\n",
    "# Example uses:\n",
    "# 1. Allow BOTH All-Purpose and Serverless:\n",
    "#    compute_validation(recommend_dbr_classic_version=17.3, recommended_serverless_version=1)\n",
    "#\n",
    "# 2. Require ONLY All-Purpose (minimum DBR version 16.4):\n",
    "#    compute_validation(recommend_dbr_classic_version=16.4, recommended_serverless_version=None)\n",
    "#\n",
    "# 3. Require ONLY Serverless (minimum version 3):\n",
    "#    compute_validation(recommend_dbr_classic_version=None, recommended_serverless_version=3)\n",
    "# -----------------------------------------------\n",
    "\n",
    "\n",
    "import os\n",
    "def _get_env():\n",
    "    \"\"\"\n",
    "    Read the Databricks compute environment and extract both All Purpose or Serverless versions.\n",
    "\n",
    "    Behavior assumptions:\n",
    "      - Serverless runtime values look like 'client.X.Y'. The middle token (X) is used as the Serverless version.\n",
    "      - All Purpose runtime values look like '17.3'. The full string is converted to float.\n",
    "      - IS_SERVERLESS may appear as 'TRUE', 'true', or be absent. The value is uppercased.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict containing:\n",
    "      - is_serverless: 'TRUE' or 'FALSE'\n",
    "      - current_serverless_version: int or None\n",
    "      - current_dbr_version_all_purpose: float or None\n",
    "    \"\"\"\n",
    "   \n",
    "    # Note: IS_SERVERLESS may be 'TRUE' or 'true' in some envs, or absent. Uppercase the string\n",
    "    is_serverless = os.environ.get(\"IS_SERVERLESS\", \"FALSE\").upper()\n",
    "    runtime_version = os.environ.get(\"DATABRICKS_RUNTIME_VERSION\", \"\")\n",
    "\n",
    "    # Serverless: require IS_SERVERLESS == 'TRUE', then extract the second token from 'client.X.Y'\n",
    "    if is_serverless == 'TRUE':\n",
    "        current_serverless_version = int(runtime_version.split(\".\")[1])\n",
    "    else:\n",
    "        current_serverless_version = None\n",
    "\n",
    "    # All Purpose: Serverless is set to FALSE in the env variable\n",
    "    if is_serverless == 'FALSE':\n",
    "        current_dbr_version_all_purpose = float(runtime_version)\n",
    "    else:\n",
    "        current_dbr_version_all_purpose = None\n",
    "\n",
    "    return {\n",
    "        'is_serverless': is_serverless,\n",
    "        'current_serverless_version':current_serverless_version, \n",
    "        'current_dbr_version_all_purpose':current_dbr_version_all_purpose\n",
    "    }\n",
    "\n",
    "\n",
    "def _check_serverless_only(current_serverless_version, recommended_serverless_version: int):\n",
    "    \"\"\"\n",
    "    Validate only the Serverless requirement path and report status.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"NOTE: This notebook was tested on Serverless compute version {recommended_serverless_version}. Checking compute...\")\n",
    "\n",
    "    if current_serverless_version is None:\n",
    "        print(f\"⚠️ WARNING: This notebook was not tested on All Purpose compute. Unexpected results or errors might occur. Please select the recommended Serverless compute version '{recommended_serverless_version}'.\")\n",
    "    elif current_serverless_version == recommended_serverless_version:\n",
    "        print(f\"✅ Serverless environment check passed: Serverless version '{current_serverless_version}' matches the recommended version.\")\n",
    "    else:\n",
    "        print(f\"⚠️ WARNING: This notebook was not tested on Serverless version '{current_serverless_version}'. Unexpected results or errors might occur. Please use Serverless version '{recommended_serverless_version}'.\")\n",
    "\n",
    "\n",
    "def _check_all_purpose_only(current_dbr_version_all_purpose, recommend_dbr_classic_version: float):\n",
    "    \"\"\"\n",
    "    Validate only the All Purpose requirement path and report status.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"NOTE: This notebook was tested on All Purpose compute DBR version {recommend_dbr_classic_version}. Checking compute...\")\n",
    "\n",
    "    if current_dbr_version_all_purpose is None:\n",
    "        print(f\"⚠️ WARNING: This notebook was not tested on Serverless compute. Unexpected results or errors might occur. Please select the recommended All Purpose compute DBR version '{recommend_dbr_classic_version}'.\")\n",
    "    elif current_dbr_version_all_purpose == recommend_dbr_classic_version:\n",
    "        print(f\"✅ All Purpose compute DBR version check passed: DBR version '{current_dbr_version_all_purpose}' matches the recommended version.\")\n",
    "    else:\n",
    "        print(f\"⚠️ WARNING: This notebook was not tested on All Purpose compute DBR version '{current_dbr_version_all_purpose}'. Unexpected results or errors might occur. Please use the recommended All Purpose compute DBR version '{recommend_dbr_classic_version}'.\")\n",
    "\n",
    "\n",
    "def _check_both(\n",
    "    recommended_serverless_version: int, \n",
    "    recommend_dbr_classic_version: float,\n",
    "    current_serverless_version: int, \n",
    "    current_dbr_version_all_purpose: float\n",
    "):\n",
    "    \"\"\"\n",
    "    Validate when either All Purpose or Serverless is acceptable and report both paths.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"NOTE: This notebook can run on either All Purpose compute (recommended DBR {recommend_dbr_classic_version}) or Serverless compute (recommended version {recommended_serverless_version}).\")\n",
    "    print(\"Checking compute...\")\n",
    "\n",
    "    # All Purpose path\n",
    "    if current_dbr_version_all_purpose is None:\n",
    "        pass\n",
    "    elif current_dbr_version_all_purpose == recommend_dbr_classic_version:\n",
    "        print(f\"✅ All Purpose compute DBR version check passed: DBR '{recommend_dbr_classic_version}' is the recommended version.\")\n",
    "    else:\n",
    "        print(f\"⚠️ WARNING: This notebook was not tested on All Purpose compute DBR version '{current_dbr_version_all_purpose}'. Unexpected results or errors might occur. Please use the recommended All Purpose DBR version '{recommend_dbr_classic_version}'.\")\n",
    "\n",
    "    # Serverless path\n",
    "    if current_serverless_version is None:\n",
    "        pass\n",
    "    elif current_serverless_version == recommended_serverless_version:\n",
    "        print(f\"✅ Serverless environment check passed: Serverless version '{recommended_serverless_version}' is the recommended version.\")\n",
    "    else:\n",
    "        print(f\"⚠️ WARNING: This notebook was not tested on Serverless version '{current_serverless_version}'. Unexpected results or errors might occur. Please use the recommended Serverless version '{recommended_serverless_version}'.\")\n",
    "\n",
    "\n",
    "##\n",
    "## Full function\n",
    "##\n",
    "def compute_validation(\n",
    "    recommended_serverless_version: int = None, \n",
    "    recommend_dbr_classic_version: float = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Check the Databricks compute environment and warn users when they are not running on the\n",
    "    compute type or version this notebook was tested on.\n",
    "\n",
    "    The function supports three cases:\n",
    "      - Serverless only: provide `recommended_serverless_version`.\n",
    "      - All Purpose only: provide `recommend_dbr_classic_version`.\n",
    "      - Either compute type: provide both.\n",
    "\n",
    "    The check compares the exact versions detected in the environment with the versions provided\n",
    "    and prints warnings if they do not match. It does not raise errors for mismatches, only for\n",
    "    missing inputs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    recommended_serverless_version : int or None\n",
    "        Expected Serverless version this notebook was validated on.\n",
    "    recommend_dbr_classic_version : float or None\n",
    "        Expected All Purpose DBR version this notebook was validated on.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Prints validation messages directly to the notebook output.\n",
    "    \"\"\"\n",
    "    ## Add line break\n",
    "\n",
    "    print('\\n')\n",
    "    # Require at least one target compute (can use both)\n",
    "    if recommended_serverless_version is None and recommend_dbr_classic_version is None:\n",
    "        raise ValueError(\n",
    "            \"Serverless version or DBR version was not specified in the function. Please specify a compute type to check.\"\n",
    "        )\n",
    "\n",
    "    # Get environment variable values\n",
    "    env_values = _get_env()\n",
    "    is_serverless = env_values[\"is_serverless\"]   ## If it's running serverless or not\n",
    "    current_serverless_version = env_values[\"current_serverless_version\"] \n",
    "    current_dbr_version_all_purpose = env_values[\"current_dbr_version_all_purpose\"] \n",
    "\n",
    "\n",
    "    # Perform checks: serverless only\n",
    "    if recommended_serverless_version is not None and recommend_dbr_classic_version is None:\n",
    "        _check_serverless_only(current_serverless_version, recommended_serverless_version)\n",
    "\n",
    "    # Perform checks: all purpose only\n",
    "    if recommended_serverless_version is None and recommend_dbr_classic_version is not None:\n",
    "        _check_all_purpose_only(current_dbr_version_all_purpose, recommend_dbr_classic_version)\n",
    "\n",
    "    # Perform checks: either path acceptable\n",
    "    if recommended_serverless_version is not None and recommend_dbr_classic_version is not None:\n",
    "        _check_both(\n",
    "            recommended_serverless_version=recommended_serverless_version, \n",
    "            recommend_dbr_classic_version=recommend_dbr_classic_version,\n",
    "            current_serverless_version=current_serverless_version,\n",
    "            current_dbr_version_all_purpose=current_dbr_version_all_purpose\n",
    "        )\n",
    "\n",
    "    ## Add line break for clarity in the output\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4fbec40-0de9-4086-bca5-dd59e60ee059",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# CHECK REQUIRED VARIABLES FUNCTION (STRICT VERSION)\n",
    "# -----------------------------------------------\n",
    "\n",
    "def check_required_vars(*var_names: str) -> bool:\n",
    "    \"\"\"\n",
    "    Validate that specified variables exist in the global scope and contain non-empty values.\n",
    "\n",
    "    This function checks whether each provided variable name exists as a global variable.\n",
    "    If any variable is missing or empty (None or an empty string), it raises a ValueError\n",
    "    and stops execution with a clear message listing the problematic variables.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    *var_names : str\n",
    "        One or more variable names (as strings) to verify.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if all required variables exist and have valid, non-empty values.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If one or more variables are missing or empty.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> your_marketplace_share_catalog_name = \"retail_share\"\n",
    "    >>> my_catalog = \"peter_catalog\"\n",
    "    >>> check_required_vars(\"your_marketplace_share_catalog_name\", \"my_catalog\")\n",
    "    ✅ All required variables are defined and have valid values:\n",
    "      - your_marketplace_share_catalog_name = retail_share\n",
    "      - my_catalog = peter_catalog\n",
    "\n",
    "    >>> check_required_vars(\"missing_var\")\n",
    "    ValueError: Variable check failed:\n",
    "    ❌ Missing variables: missing_var\n",
    "    \"\"\"\n",
    "    missing = []\n",
    "    empty = []\n",
    "    globals_ = globals()\n",
    "    valid = {}\n",
    "\n",
    "    for name in var_names:\n",
    "        if name not in globals_:\n",
    "            missing.append(name)\n",
    "        else:\n",
    "            val = globals_[name]\n",
    "            if val is None or (isinstance(val, str) and val.strip() == \"\"):\n",
    "                empty.append(name)\n",
    "            else:\n",
    "                valid[name] = val\n",
    "\n",
    "    if missing or empty:\n",
    "        msg = []\n",
    "        if missing:\n",
    "            msg.append(f\"❌ The following python variables were not set: {', '.join(missing)}. \\n Please review the classroom setup and set the variables following the instructions\")\n",
    "        if empty:\n",
    "            msg.append(f\"⚠️ Empty variables: {', '.join(empty)}\")\n",
    "        full_msg = \"\\n\".join(msg)\n",
    "        raise ValueError(f\"Variable check failed:\\n{full_msg}\")\n",
    "\n",
    "    print(\"✅ All required variables are defined and have the following values:\")\n",
    "    for name, val in valid.items():\n",
    "        print(f\"  - {name} = {val}\")\n",
    "    \n",
    "    ## Add line breaks for clarity in the output\n",
    "    print('\\n')\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "499e1270-ff85-4503-a961-e8b94171ad7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def display_config_values(config_values):\n",
    "    \"\"\"\n",
    "    Displays list of key-value pairs as rows of HTML text and textboxes\n",
    "    \n",
    "    param config_values: \n",
    "        list of (key, value) tuples\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    HTML output displaying the config values\n",
    "    Example\n",
    "    --------\n",
    "    display_config_values([('catalog', 'your catalog'),('schema','your schema')])\n",
    "    \"\"\"\n",
    "    html = \"\"\"<table style=\"width:100%\">\"\"\"\n",
    "    for name, value in config_values:\n",
    "        html += f\"\"\"\n",
    "        <tr>\n",
    "            <td style=\"white-space:nowrap; width:1em\">{name}:</td>\n",
    "            <td><input type=\"text\" value=\"{value}\" style=\"width: 100%\"></td></tr>\"\"\"\n",
    "    html += \"</table>\"\n",
    "    displayHTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26088e5f-4eb0-42cb-a10e-766251579461",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def setup_complete_msg():\n",
    "  '''\n",
    "  Prints a note in the output that the setup was complete.\n",
    "  '''\n",
    "  print('\\n------------------------------------------------------------------------------')\n",
    "  print('✅ SETUP COMPLETE!')\n",
    "  print('------------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4983435480755671,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Classroom-Setup-Common",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
